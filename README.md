# ğŸ‡§ğŸ‡· Brazilian Fraud Data Generator

<div align="center">

[![en](https://img.shields.io/badge/lang-en-red.svg)](./README.md)
[![pt-br](https://img.shields.io/badge/lang-pt--br-green.svg)](./README.pt-BR.md)

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)
[![Docker Hub](https://img.shields.io/docker/v/afborda/brazilian-fraud-data-generator?label=Docker%20Hub&logo=docker)](https://hub.docker.com/r/afborda/brazilian-fraud-data-generator)
[![Docker Pulls](https://img.shields.io/docker/pulls/afborda/brazilian-fraud-data-generator?logo=docker)](https://hub.docker.com/r/afborda/brazilian-fraud-data-generator)
![Kafka](https://img.shields.io/badge/Kafka-Streaming-231F20?logo=apachekafka&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-S3-C72E49?logo=minio&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-blue)

**Generate realistic Brazilian banking and ride-share data for Data Engineering & ML**

</div>

---

## ğŸ¯ What is this?

A tool to generate **synthetic Brazilian data** for:
- ğŸ¦ **Banking transactions** (PIX, cards, TED, boleto)
- ğŸš— **Ride-share trips** (Uber, 99, Cabify, InDriver)
- ğŸ”´ **Fraud detection** training and testing

Perfect for: **Data pipelines**, **Spark jobs**, **Kafka streaming**, **ML models**, **API testing**

---

## ğŸš€ 5-Minute Quick Start

### 1ï¸âƒ£ Install

```bash
git clone https://github.com/afborda/brazilian-fraud-data-generator.git
cd brazilian-fraud-data-generator
pip install -r requirements.txt
```

### 2ï¸âƒ£ Generate Your First Data

```bash
# Generate 100MB of transactions
python3 generate.py --size 100MB --output ./my_data
```

**That's it!** Check your `./my_data` folder:
```
my_data/
â”œâ”€â”€ customers.jsonl       # ğŸ‘¥ Customers with valid CPFs
â”œâ”€â”€ devices.jsonl         # ğŸ“± Devices per customer  
â””â”€â”€ transactions_00000.jsonl  # ğŸ’³ Transactions (~128MB each)
```

---

## ğŸ“– Data Types: Banking vs Ride-Share

This generator supports **two different types** of data:

| Type | Command | What it generates | Fraud types |
|------|---------|-------------------|-------------|
| ğŸ’³ **Banking** | `--type transactions` | PIX, cards, TED, boleto | Card cloning, account takeover, social engineering |
| ğŸš— **Ride-Share** | `--type rides` | Uber, 99, Cabify, InDriver trips | GPS spoofing, fake rides, driver collusion |
| ğŸ”„ **Both** | `--type all` | All of the above | All fraud types |

### Output Files by Type

```bash
# Banking (default): --type transactions
output/
â”œâ”€â”€ customers.jsonl          # ğŸ‘¥ Bank customers
â”œâ”€â”€ devices.jsonl            # ğŸ“± Customer devices
â””â”€â”€ transactions_*.jsonl     # ğŸ’³ Banking transactions

# Ride-Share: --type rides
output/
â”œâ”€â”€ customers.jsonl          # ğŸ‘¥ Passengers
â”œâ”€â”€ devices.jsonl            # ğŸ“± Passenger devices
â”œâ”€â”€ drivers.jsonl            # ğŸš˜ Drivers with vehicles
â””â”€â”€ rides_*.jsonl            # ğŸš— Ride-share trips

# Both: --type all
output/
â”œâ”€â”€ customers.jsonl          # ğŸ‘¥ Customers/Passengers
â”œâ”€â”€ devices.jsonl            # ğŸ“± Devices
â”œâ”€â”€ drivers.jsonl            # ğŸš˜ Drivers
â”œâ”€â”€ transactions_*.jsonl     # ğŸ’³ Banking transactions
â””â”€â”€ rides_*.jsonl            # ğŸš— Ride-share trips
```

---

## ğŸ“– Usage Examples

### ğŸ”¹ Batch Mode (Generate Files)

| Goal | Command |
|------|---------|
| Generate 1GB of transactions | `python3 generate.py --size 1GB` |
| Generate in CSV format | `python3 generate.py --size 500MB --format csv` |
| Generate in Parquet | `python3 generate.py --size 1GB --format parquet` |
| Generate ride-share data | `python3 generate.py --size 1GB --type rides` |
| Generate both (transactions + rides) | `python3 generate.py --size 1GB --type all` |
| Higher fraud rate (5%) | `python3 generate.py --size 1GB --fraud-rate 0.05` |
| Reproducible data (seed) | `python3 generate.py --size 1GB --seed 42` |
| Faster with 16 workers | `python3 generate.py --size 10GB --workers 16` |

#### ğŸ—œï¸ Parquet Compression Options

When using `--format parquet`, you can choose the compression algorithm:

| Compression | Command | Best For |
|-------------|---------|----------|
| **ZSTD** (default) | `--compression zstd` | Best compression ratio, recommended |
| Snappy | `--compression snappy` | Faster, legacy compatibility |
| Gzip | `--compression gzip` | Maximum compatibility |
| Brotli | `--compression brotli` | High compression |
| None | `--compression none` | No compression |

```bash
# Default: ZSTD (best compression/speed ratio, ~91% smaller than JSONL)
python3 generate.py --size 1GB --format parquet

# Use Snappy for legacy systems or Spark < 2.4
python3 generate.py --size 1GB --format parquet --compression snappy

# Maximum compression with Gzip
python3 generate.py --size 1GB --format parquet --compression gzip
```

> **ğŸ’¡ Note:** ZSTD is the default because it offers the best balance of compression ratio and speed. 
> If your system doesn't support ZSTD (older Spark, Hive, or Presto versions), use `--compression snappy`.

### ğŸ”¹ Streaming Mode (Real-time)

First, install streaming dependencies:
```bash
pip install -r requirements-streaming.txt
```

| Goal | Command |
|------|---------|
| Test in terminal (5/sec) | `python3 stream.py --target stdout --rate 5` |
| Stream to Kafka | `python3 stream.py --target kafka --kafka-server localhost:9092 --rate 100` |
| Stream rides to Kafka | `python3 stream.py --target kafka --type rides --kafka-topic rides --rate 50` |
| Stream to REST API | `python3 stream.py --target webhook --webhook-url http://api:8080/ingest` |
| Limited events (1000) | `python3 stream.py --target stdout --max-events 1000` |

#### ğŸ“Š Understanding `--rate` (Events per Second)

| Rate | Meaning | Use Case |
|------|---------|----------|
| `--rate 1` | 1 event/sec (1 per 1000ms) | Debug/Testing |
| `--rate 10` | 10 events/sec (1 per 100ms) | Development |
| `--rate 100` | 100 events/sec (1 per 10ms) | Production |
| `--rate 1000` | 1000 events/sec (1 per 1ms) | Stress test |

**Real-time output shows actual throughput:**
```
ğŸ“Š Events: 1,000 | Rate: 99.6/s | Errors: 0
```

### ğŸ”¹ Docker Mode

#### Using Docker Hub (Recommended)

```bash
# Pull the latest version
docker pull afborda/brazilian-fraud-data-generator:latest

# Generate 1GB of transactions
docker run --rm -v $(pwd)/output:/output afborda/brazilian-fraud-data-generator:latest \
    generate.py --size 1GB --output /output

# Generate in Parquet format
docker run --rm -v $(pwd)/output:/output afborda/brazilian-fraud-data-generator:latest \
    generate.py --size 500MB --output /output --format parquet

# Generate ride-share data
docker run --rm -v $(pwd)/output:/output afborda/brazilian-fraud-data-generator:latest \
    generate.py --size 1GB --type rides --output /output

# Streaming to Kafka
docker run --rm --network host afborda/brazilian-fraud-data-generator:latest \
    stream.py --target kafka --kafka-server localhost:9092 --rate 100
```

#### Using Local Build

```bash
# Build the image locally
docker build -t fraud-generator .

# Batch: Generate 1GB
docker run --rm -v $(pwd)/output:/output fraud-generator \
    generate.py --size 1GB --output /output

# Streaming to Kafka
docker run --rm --network host fraud-generator \
    stream.py --target kafka --kafka-server localhost:9092 --rate 100
```

### ğŸ”¹ MinIO/S3 Direct Upload

Upload directly to MinIO or S3-compatible storage:

```bash
# Upload to MinIO bucket
python3 generate.py --size 1GB \
    --output minio://fraud-data/raw \
    --minio-endpoint http://localhost:9000 \
    --minio-access-key minioadmin \
    --minio-secret-key minioadmin

# Or use environment variables
export MINIO_ENDPOINT=http://localhost:9000
export MINIO_ROOT_USER=minioadmin
export MINIO_ROOT_PASSWORD=minioadmin

python3 generate.py --size 1GB --output minio://fraud-data/raw
```

---

## ğŸ“Š What Data is Generated?

### ğŸ‘¥ Customers

```json
{
  "customer_id": "CUST_000000000001",
  "name": "Maria Silva Santos",
  "cpf": "123.456.789-09",
  "email": "maria.silva@email.com.br",
  "phone": "(11) 98765-4321",
  "birth_date": "1985-03-15",
  "address": {
    "city": "SÃ£o Paulo",
    "state": "SP",
    "postal_code": "01310-100"
  },
  "monthly_income": 5500.00,
  "bank_name": "Nubank",
  "behavioral_profile": "young_digital"
}
```

### ğŸ’³ Transactions

```json
{
  "transaction_id": "TXN_000000000000001",
  "customer_id": "CUST_000000000001",
  "timestamp": "2024-03-15T14:32:45",
  "type": "PIX",
  "amount": 150.00,
  "merchant_name": "Carrefour",
  "is_fraud": false,
  "fraud_type": null,
  "fraud_score": 12.5
}
```

### ğŸš— Rides

```json
{
  "ride_id": "RIDE_000000000001",
  "timestamp": "2024-03-15T14:32:45",
  "app": "UBER",
  "category": "UberX",
  "driver_id": "DRV_0000000001",
  "passenger_id": "CUST_000000000001",
  "pickup_location": { "city": "SÃ£o Paulo", "state": "SP" },
  "dropoff_location": { "city": "SÃ£o Paulo", "state": "SP" },
  "distance_km": 8.5,
  "final_fare": 27.75,
  "payment_method": "PIX",
  "is_fraud": false
}
```

### ğŸš˜ Drivers

```json
{
  "driver_id": "DRV_0000000001",
  "name": "JoÃ£o Carlos Silva",
  "cpf": "987.654.321-00",
  "vehicle_plate": "ABC1D23",
  "vehicle_model": "HB20",
  "rating": 4.85,
  "active_apps": ["UBER", "99"],
  "operating_city": "SÃ£o Paulo"
}
```

---

## ğŸ”´ Fraud Types

### Transaction Frauds (13 types)

| Type | Description |
|------|-------------|
| `ENGENHARIA_SOCIAL` | Phone/WhatsApp scams |
| `CONTA_TOMADA` | Account takeover |
| `CARTAO_CLONADO` | Cloned card |
| `IDENTIDADE_FALSA` | Fake documents |
| `SIM_SWAP` | SIM card fraud |
| `TESTE_CARTAO` | Card testing |
| `LAVAGEM_DINHEIRO` | Money laundering |
| ... | + 6 more |

### Ride Frauds (7 types)

| Type | Description |
|------|-------------|
| `GPS_SPOOFING` | Fake GPS to increase distance |
| `DRIVER_COLLUSION` | Driver-passenger fake rides |
| `SURGE_ABUSE` | Artificial surge pricing |
| `PROMO_ABUSE` | Promotional code abuse |
| `FAKE_RIDE` | Fake ride for payout |
| `IDENTITY_FRAUD` | Fake driver/passenger identity |
| `PAYMENT_FRAUD` | Stolen payment methods |

---

## âš™ï¸ All Parameters

### generate.py (Batch Mode)

```bash
python3 generate.py --help
```

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--size`, `-s` | `1GB` | Target size: `100MB`, `1GB`, `50GB` |
| `--type`, `-t` | `transactions` | `transactions`, `rides`, or `all` |
| `--output`, `-o` | `./output` | Output dir or `minio://bucket/prefix` |
| `--format`, `-f` | `jsonl` | `jsonl`, `csv`, `parquet` |
| `--fraud-rate`, `-r` | `0.02` | Fraud rate (0.0 to 1.0) |
| `--workers`, `-w` | `CPU cores` | Parallel workers |
| `--seed` | None | Seed for reproducibility |
| `--customers`, `-c` | Auto | Number of customers |
| `--start-date` | -1 year | Start date (YYYY-MM-DD) |
| `--end-date` | today | End date (YYYY-MM-DD) |
| `--no-profiles` | - | Disable behavioral profiles |
| `--minio-endpoint` | env | MinIO/S3 endpoint URL |
| `--minio-access-key` | env | MinIO access key |
| `--minio-secret-key` | env | MinIO secret key |

### stream.py (Streaming Mode)

```bash
python3 stream.py --help
```

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--target`, `-t` | Required | `stdout`, `kafka`, `webhook` |
| `--type` | `transactions` | `transactions` or `rides` |
| `--rate`, `-r` | `10` | Events per second |
| `--max-events`, `-n` | âˆ | Stop after N events |
| `--customers`, `-c` | `1000` | Customer pool size |
| `--fraud-rate` | `0.02` | Fraud rate |
| `--kafka-server` | `localhost:9092` | Kafka bootstrap server |
| `--kafka-topic` | `transactions` | Kafka topic |
| `--webhook-url` | - | Webhook endpoint |
| `--quiet`, `-q` | - | Suppress progress output |

---

## ğŸ³ Docker Compose (Full Stack)

Run with Kafka included:

```yaml
# docker-compose.yml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

  fraud-generator:
    build: .
    depends_on: [kafka]
    command: >
      python3 stream.py 
        --target kafka 
        --kafka-server kafka:29092 
        --kafka-topic transactions 
        --rate 10
```

```bash
docker-compose up -d
docker-compose logs -f fraud-generator
```

---

## ğŸ”Œ Integration Examples

### Apache Spark

```python
# Read generated data
df = spark.read.json("output/transactions_*.jsonl")

# Analyze frauds
df.filter("is_fraud = true") \
  .groupBy("fraud_type") \
  .count() \
  .show()
```

### Kafka Consumer (Python)

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'transactions',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

for message in consumer:
    tx = message.value
    if tx['is_fraud']:
        print(f"ğŸš¨ FRAUD: {tx['transaction_id']} - {tx['fraud_type']}")
```

### Pandas / ML Training

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Load data
df = pd.read_json("output/transactions_00000.jsonl", lines=True)

# Prepare features
X = df[['valor', 'fraud_score', 'horario_incomum']]
y = df['is_fraud']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

### MinIO + Spark (Data Lake)

```python
# Configure Spark for MinIO
spark = SparkSession.builder \
    .config("spark.hadoop.fs.s3a.endpoint", "http://localhost:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.secret.key", "minioadmin") \
    .getOrCreate()

# Read from MinIO
df = spark.read.json("s3a://fraud-data/raw/transactions_*.jsonl")
```

---

## ğŸ“ Project Structure

```
brazilian-fraud-data-generator/
â”œâ”€â”€ generate.py              # ğŸ“ Batch generation script
â”œâ”€â”€ stream.py                # ğŸ“¡ Streaming script
â”œâ”€â”€ Dockerfile               # ğŸ³ Docker image
â”œâ”€â”€ docker-compose.yml       # ğŸ³ Full stack with Kafka
â”œâ”€â”€ requirements.txt         # ğŸ“¦ Core dependencies
â”œâ”€â”€ requirements-streaming.txt # ğŸ“¦ Kafka/webhook deps
â”‚
â””â”€â”€ src/fraud_generator/
    â”œâ”€â”€ generators/          # Customer, Device, Transaction, Driver, Ride
    â”œâ”€â”€ exporters/           # JSON, CSV, Parquet, MinIO
    â”œâ”€â”€ connections/         # Kafka, Webhook, Stdout
    â”œâ”€â”€ validators/          # CPF validation
    â”œâ”€â”€ profiles/            # Behavioral profiles
    â””â”€â”€ config/              # Banks, MCCs, Geography
```

---

## ğŸ¦ Supported Banks (25+)

| Bank | Type | Share |
|------|------|-------|
| Nubank | Digital | 15% |
| Banco do Brasil | Public | 15% |
| ItaÃº | Private | 15% |
| Caixa | Public | 14% |
| Bradesco | Private | 12% |
| Santander | Private | 10% |
| Inter, C6, PagBank, Original... | Digital | ... |

---

## ğŸ‘¤ Behavioral Profiles

| Profile | % | Behavior |
|---------|---|----------|
| `young_digital` | 25% | PIX, streaming, delivery apps |
| `family_provider` | 22% | Supermarket, utilities, education |
| `subscription_heavy` | 20% | Recurring, digital services |
| `traditional_senior` | 15% | Cards, pharmacies |
| `business_owner` | 10% | B2B, high values |
| `high_spender` | 8% | Luxury, travel |

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)

---

## ğŸ‘¤ Author

**Abner Fonseca** - [@afborda](https://github.com/afborda)

---

<div align="center">

â­ **Star this repo if it helped you-rf /home/ubuntu/Estudos/brazilian-fraud-data-generator/test_output* â­

Made with â¤ï¸ for the Brazilian Data Engineering community

</div>
