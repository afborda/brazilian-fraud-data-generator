# ğŸ‡§ğŸ‡· Brazilian Fraud Data Generator

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python&logoColor=white)
![Faker](https://img.shields.io/badge/Faker-pt__BR-green)
![License](https://img.shields.io/badge/License-MIT-blue)
[![Stars](https://img.shields.io/github/stars/afborda/brazilian-fraud-data-generator?style=social)](https://github.com/afborda/brazilian-fraud-data-generator)

**Gerador de dados sintÃ©ticos de transaÃ§Ãµes bancÃ¡rias brasileiras para estudos de Data Engineering e Machine Learning**

[ğŸš€ Quick Start](#-quick-start) â€¢
[ğŸ“Š Dados Gerados](#-dados-gerados) â€¢
[âš™ï¸ ParÃ¢metros](#ï¸-parÃ¢metros) â€¢
[ğŸ¯ Casos de Uso](#-casos-de-uso)

</div>

---

## ğŸ“‹ Sobre

Este projeto gera **dados sintÃ©ticos realistas** de transaÃ§Ãµes bancÃ¡rias brasileiras, incluindo:

- âœ… **Clientes** com CPF, nome, endereÃ§o (Faker pt_BR)
- âœ… **Dispositivos** (smartphones, tablets, desktops)
- âœ… **TransaÃ§Ãµes** (PIX, cartÃ£o, TED, boleto)
- âœ… **Fraudes** (8 tipos diferentes com taxa configurÃ¡vel)
- âœ… **GeolocalizaÃ§Ã£o** brasileira real
- âœ… **Bancos** reais (cÃ³digos BACEN)

### ğŸ¯ Por que foi criado?

Estudando **Data Engineering**, precisei de um dataset grande e realista para:
- Testar pipelines Apache Spark em escala
- Praticar arquitetura Medallion (Bronze â†’ Silver â†’ Gold)
- Treinar modelos de detecÃ§Ã£o de fraude
- Simular cenÃ¡rios de Big Data (50GB+)

NÃ£o encontrei datasets brasileiros de qualidade, entÃ£o criei este gerador!

---

## ğŸš€ Quick Start

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/afborda/brazilian-fraud-data-generator.git
cd brazilian-fraud-data-generator

# Instale as dependÃªncias
pip install -r requirements.txt
```

### Gerar dados

```bash
# Gerar 1GB de dados (teste rÃ¡pido)
python generate.py --size 1GB

# Gerar 10GB de dados
python generate.py --size 10GB --workers 4

# Gerar 50GB de dados (recomendado para Big Data)
python generate.py --size 50GB --workers 8
```

### Resultado

```
data/
â”œâ”€â”€ customers.json      # 100K clientes brasileiros
â”œâ”€â”€ devices.json        # 300K dispositivos
â””â”€â”€ transactions_*.json # Arquivos de 128MB cada
```

---

## âš™ï¸ ParÃ¢metros

| ParÃ¢metro | PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------|-----------|
| `--size` | `1GB` | Tamanho total dos dados (ex: `1GB`, `10GB`, `50GB`) |
| `--workers` | `CPU cores` | NÃºmero de processos paralelos |
| `--fraud-rate` | `0.007` | Taxa de fraude (0.7% = ~7 a cada 1000) |
| `--output` | `./data` | DiretÃ³rio de saÃ­da |
| `--customers` | `100000` | NÃºmero de clientes a gerar |
| `--devices-per-customer` | `3` | Dispositivos por cliente |

### Exemplos

```bash
# Teste rÃ¡pido (500MB, 2 workers)
python generate.py --size 500MB --workers 2

# ProduÃ§Ã£o (50GB, mÃ¡ximo de workers, 1% fraude)
python generate.py --size 50GB --workers 10 --fraud-rate 0.01

# Customizado (20GB, 200K clientes)
python generate.py --size 20GB --customers 200000 --output ./meus_dados
```

---

## ğŸ“Š Dados Gerados

### ğŸ‘¥ Clientes (`customers.json`)

```json
{
  "customer_id": "CUST_00000001",
  "nome": "Maria Silva Santos",
  "cpf": "123.456.789-00",
  "data_nascimento": "1985-03-15",
  "email": "maria.silva@email.com.br",
  "telefone": "(11) 98765-4321",
  "endereco": {
    "logradouro": "Rua das Flores, 123",
    "bairro": "Centro",
    "cidade": "SÃ£o Paulo",
    "estado": "SP",
    "cep": "01310-100"
  },
  "renda_mensal": 5500.00,
  "score_credito": 750,
  "banco_principal": "341",
  "conta_desde": "2018-06-01"
}
```

### ğŸ“± Dispositivos (`devices.json`)

```json
{
  "device_id": "DEV_00000001",
  "customer_id": "CUST_00000001",
  "tipo": "SMARTPHONE",
  "fabricante": "Samsung",
  "modelo": "Galaxy S21",
  "sistema_operacional": "Android 13",
  "fingerprint": "a1b2c3d4e5f6...",
  "primeiro_uso": "2023-01-15",
  "is_trusted": true
}
```

### ğŸ’³ TransaÃ§Ãµes (`transactions_*.json`)

```json
{
  "transaction_id": "TXN_000000000000001",
  "customer_id": "CUST_00000001",
  "device_id": "DEV_00000001",
  "timestamp": "2024-03-15T14:32:45",
  "tipo": "PIX",
  "valor": 150.00,
  "moeda": "BRL",
  "canal": "APP_MOBILE",
  "ip_address": "177.45.123.89",
  "geolocalizacao_lat": -23.550520,
  "geolocalizacao_lon": -46.633308,
  "merchant_name": "Supermercado Extra",
  "merchant_category": "Supermercados",
  "mcc_code": "5411",
  "chave_pix_tipo": "CPF",
  "chave_pix_destino": "123.456.789-00",
  "banco_destino": "341",
  "fraud_score": 12.5,
  "is_fraud": false,
  "fraud_type": null,
  "status": "APROVADA"
}
```

---

## ğŸš¨ Tipos de Fraude

O gerador inclui **8 tipos de fraude** baseados em cenÃ¡rios reais:

| Tipo | DescriÃ§Ã£o | % do Total |
|------|-----------|------------|
| `CARTAO_CLONADO` | CartÃ£o fÃ­sico/dados clonados | ~15% |
| `CONTA_TOMADA` | Account takeover | ~15% |
| `IDENTIDADE_FALSA` | Documentos falsos | ~12% |
| `ENGENHARIA_SOCIAL` | Golpes por telefone/WhatsApp | ~18% |
| `LAVAGEM_DINHEIRO` | TransaÃ§Ãµes de lavagem | ~10% |
| `AUTOFRAUDE` | Cliente alega fraude falsa | ~12% |
| `FRAUDE_AMIGAVEL` | Fraude por conhecidos | ~10% |
| `TRIANGULACAO` | Fraude com intermediÃ¡rios | ~8% |

---

## ğŸ“ˆ Performance

Testado em VPS com 8 cores / 24GB RAM:

| Tamanho | Arquivos | Tempo | Velocidade |
|---------|----------|-------|------------|
| 1 GB | 8 | ~1 min | 17 MB/s |
| 10 GB | 80 | ~8 min | 21 MB/s |
| 50 GB | 400 | ~35 min | 24 MB/s |

> ğŸ’¡ **Dica:** Use `--workers` igual ao nÃºmero de cores da CPU para mÃ¡xima performance

---

## ğŸ¯ Casos de Uso

### 1ï¸âƒ£ Estudar Apache Spark

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("FraudAnalysis").getOrCreate()

# Ler transaÃ§Ãµes
df = spark.read.json("data/transactions_*.json")
df.printSchema()
df.show()

# AnÃ¡lise de fraudes
df.filter("is_fraud = true").groupBy("fraud_type").count().show()
```

### 2ï¸âƒ£ Treinar modelo de ML

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# Carregar dados
df = pd.read_json("data/transactions_00000.json", lines=True)

# Features
X = df[['valor', 'fraud_score', 'transacoes_ultimas_24h']]
y = df['is_fraud']

# Treinar
model = RandomForestClassifier()
model.fit(X, y)
```

### 3ï¸âƒ£ Pipeline Medallion

```
Raw (JSON) â†’ Bronze (Parquet) â†’ Silver (Limpo) â†’ Gold (Agregado)
   51 GB   â†’      5 GB        â†’      5.4 GB    â†’     2 GB
                              90% compressÃ£o!
```

### 4ï¸âƒ£ Dashboards de BI

Conecte Metabase, PowerBI ou Tableau para criar dashboards de:
- Taxa de fraude por estado
- Tipos de fraude mais comuns
- AnÃ¡lise temporal de transaÃ§Ãµes
- Top merchants suspeitos

---

## ğŸ“ Estrutura do Projeto

```
brazilian-fraud-data-generator/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ generate.py           # Script principal
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“‚ generators/
â”‚   â”œâ”€â”€ customers.py         # Gerador de clientes
â”‚   â”œâ”€â”€ devices.py           # Gerador de dispositivos
â”‚   â””â”€â”€ transactions.py      # Gerador de transaÃ§Ãµes
â””â”€â”€ ğŸ“‚ data/                  # Dados gerados (gitignore)
    â”œâ”€â”€ customers.json
    â”œâ”€â”€ devices.json
    â””â”€â”€ transactions_*.json
```

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! 

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### Ideias para contribuir:
- [ ] Adicionar mais tipos de transaÃ§Ã£o (DOC, dÃ©bito automÃ¡tico)
- [ ] Gerar dados de cartÃµes de crÃ©dito
- [ ] Adicionar padrÃµes temporais realistas
- [ ] Suporte a outros paÃ­ses da AmÃ©rica Latina

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¤ Autor

**Abner Fonseca**
- LinkedIn: [linkedin.com/in/abnerfonseca](https://linkedin.com/in/abnerfonseca)
- GitHub: [@afborda](https://github.com/afborda)

---

## â­ Gostou?

Se este projeto te ajudou, deixa uma â­ no repositÃ³rio!

---

<div align="center">

**Feito com â¤ï¸ para a comunidade de Data Engineering brasileira**

</div>
